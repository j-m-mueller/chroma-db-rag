{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23745634-0893-4aae-9f56-6ef37f6146f4",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation using ChromaDB\n",
    "\n",
    "This notebook demonstrates Retrieval-Augmented Generation (RAG) by an LLM based on a vector DB with private data.\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [Motivation](#Motivation--What-is-RAG-and-why-do-we-need-it?)\n",
    "- [Vector DB Setup](#Vector-DB-Setup)\n",
    "- [Local LLM-based RAG (Llama 3.1)](#Local-LLM-based-RAG-(Llama-3.1))\n",
    "- [API-based RAG (OpenAI API)](#API-based-RAG:-OpenAI-API)\n",
    "\n",
    "## Motivation - What is RAG and why do we need it?\n",
    "\n",
    "While the last few years have demonstrated a huge progress in Generative AI, specifically related to Natural Language Processing (NLP) and transformer-based models, one of the key issues remains: Large Language Models (LLMs) like ChatGPT may suffer from **hallucinations**, providing misleading or false results. \n",
    "\n",
    "One way to mitigate this problem is to explicitly prompt the LLM to validate it's output based on additional data provided by an external source of data. This can happen by fact-checking the generated response or by directly enforcing generation of a response purely based on the external data source. While these approaches still exploit the general capabilities of semantic and syntactic understanding of queries and data provided via prompts, it removes the potential pitfall that the model may not have seen the data to answer the user prompt appropriately if this data is provided as an additional part of the prompt. This can reduce hallucinations.\n",
    "\n",
    "The process of using additional information from an external data source to answer the user prompt is called **Retrieval-Augmented Generation (RAG)**. This way, we can ensure that the model has all the data it needs to provide the best possible answer. As **most of the world's data is private**, this step can significantly improve the output quality.\n",
    "\n",
    "## System Configuration\n",
    "\n",
    "If we want to extract valuable information from an external data source based on the user prompt, we need to identify suitable entries in this data source for the LLM to rely on. A key concept in this context is the use of **embeddings**. \n",
    "\n",
    "### Vector DB Setup\n",
    "\n",
    "During setup of the system, we two major steps:\n",
    "\n",
    "1. We process our private data so we can feed it into a vector database. For this, we need to generate a vector that represents the data. This is commonly performed by chunking the data and generating embeddings of the text data / documents.\n",
    "2. We store the embeddings in the vector DB for rapid retrieval of the embeddings and the associated document.\n",
    "\n",
    "### Retrieval-Augmented Generation\n",
    "\n",
    "Once we have the embeddings stored in the DB, we can set up a system for processing user queries. This requires three steps:\n",
    "\n",
    "1. When the user sends a prompt, we generate an embedding of the prompt.\n",
    "2. We determine the similarity of the embedding to the embeddings stored in the vector DB (e.g., by cosine similarity) and retrieve the $\\textit{n}$ most similar documents from the vector DB based on their embeddings, given that their similarity surpasses a certain threshold.\n",
    "3. We then submit a query to the LLM in which we ask the LLM to explicitly answer the prompt based on the provided information from the vector DB.\n",
    "\n",
    "Note that depending on the quality of the embeddings, the query to the DB might result in the retrieval of similar, but unrelated documents. If not properly fine-tuned, the LLM might therefore sometimes interpret the information incorrectly.\n",
    "\n",
    "## Practical Implementation\n",
    "\n",
    "Here, we demonstrate this by providing additional information via a local ChromaDB - other vector DBs like Pinecone or FAISS are not being tested. We will use both a local LLM (Llama 3.1) and the OpenAI API for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c942e-1b0e-4067-a5d1-d199e5af46bc",
   "metadata": {},
   "source": [
    "### Vector DB Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2600fb26-d40b-46a2-a699-6c5618311d04",
   "metadata": {},
   "source": [
    "Let's set up the vector DB. Here, we will feed the ChromaDB with exemplary data from the Wikipedia API for demonstration, but you can feed it with any information you like, like PDF files, data from APIs, database systems, etc..\n",
    "\n",
    "**CAUTION: make sure not to overload the Wikipedia API!** Read the official [API documentation](https://www.mediawiki.org/wiki/Special:MyLanguage/API:Main_page) for further information prior to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "430a1e21-1632-4ace-b54c-8e9c42bc8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98973d9c-b61d-41db-84cb-7a6bfd87e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIPEDIA_API_URL = 'http://en.wikipedia.org/w/api.php'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f34367-bd72-4d06-bc2e-6d8163eee5d5",
   "metadata": {},
   "source": [
    "### Method definitions\n",
    "\n",
    "Let's define some methods to populate our text corpus by retrieving articles from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03d8221b-9622-4087-881e-f13499bf3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_page_ids(search_term: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Retrieves Wikipedia Page IDs for articles related to a search term.\n",
    "    \n",
    "    :param search_term: term to search for.\n",
    "    \n",
    "    :return: list of Page IDs.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": search_term,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = requests.get(WIKIPEDIA_API_URL,\n",
    "                            params=params)\n",
    "    data = response.json()\n",
    "    return [elem['pageid'] for elem in data['query']['search']]\n",
    "\n",
    "\n",
    "def get_wikipedia_article_by_id(page_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the full text of a Wikipedia article based on its page ID.\n",
    "\n",
    "    :param page_id: page ID of the corresponding article.\n",
    "\n",
    "    :return: full text of the article.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"pageids\": page_id,\n",
    "        \"explaintext\": True,\n",
    "        \"exlimit\": \"1\"  # return full articles\n",
    "    }\n",
    "    response = requests.get(WIKIPEDIA_API_URL,\n",
    "                            params=params)\n",
    "    data = response.json()\n",
    "    return data['query']['pages'][str(page_id)]['extract'].strip()\n",
    "\n",
    "\n",
    "def get_wikipedia_articles_by_search_term(search_term: str,\n",
    "                                          max_page_ids: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve n Wikipedia articles directly from a search term via the Page ID.\n",
    "\n",
    "    :param search_term: term to search for.\n",
    "    :param max_page_ids: maximal number of page IDs to retrieve.\n",
    "\n",
    "    :return: article contents in a list.\n",
    "    \"\"\"\n",
    "    page_ids = get_wikipedia_page_ids(search_term=search_term)\n",
    "\n",
    "    documents = []\n",
    "    for page_id in page_ids[:max_page_ids]:\n",
    "        documents.append(get_wikipedia_article_by_id(page_id=page_id))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "def get_wikipedia_articles_for_multiple_search_terms(search_terms: List[str],\n",
    "                                                     max_page_ids: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve n Wikipedia articles for multiple search terms.\n",
    "\n",
    "    Note: we are not keeping track of which article title the articles here!\n",
    "\n",
    "    :param seach_terms: list of search terms to query for.\n",
    "    :param max_page_ids: number of page IDs to extract for each search term.\n",
    "\n",
    "    :return: list of all extracted documents.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for search_term in search_terms:\n",
    "        documents.extend(\n",
    "            get_wikipedia_articles_by_search_term(search_term=search_term,\n",
    "                                                  max_page_ids=max_page_ids)\n",
    "        )\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5953d-b7e7-45ab-b582-b26bf2032bc3",
   "metadata": {},
   "source": [
    "### Method testing\n",
    "\n",
    "Briefly check whether the methods yield reasonable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5dfa8a8-c295-4649-b9e1-3c88aef7dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_wikipedia_articles_by_search_term(search_term='simulated reality',\n",
    "                                                  max_page_ids=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e43d8ad-8e79-4f49-893a-0361ed30ccec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simulated reality is an approximation of reality created in a simulation, usually in a set of circ'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbfdd5a-8a58-437c-8af9-08ef6026dde9",
   "metadata": {},
   "source": [
    "### Corpus Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd59ae-0326-45ea-b17c-51d98013bcfd",
   "metadata": {},
   "source": [
    "Let us now populate the corpus with multiple documents. We will retrieve data from 3 pages (top 3 hits) for each search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "973b83b8-3ffc-427e-89f6-233d4ae2ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['antikythera mechanism', 'simulated reality', 'large language models', 'model interpretability']\n",
    "max_page_ids = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f90ef3ba-5d8c-49bc-b8d6-8a43be180079",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = get_wikipedia_articles_for_multiple_search_terms(\n",
    "    search_terms=search_terms,\n",
    "    max_page_ids=max_page_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581505b-590e-422b-8419-20aadbff6346",
   "metadata": {},
   "source": [
    "Let's check if the expected number of documents was retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1bfc4d1-a2a2-4223-b6b0-27b6fda53ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(search_terms)*max_page_ids == len(documents), \"mismatch of expected and retrieved documents\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e429f48-f9ac-4dc1-846d-df9f1f03a674",
   "metadata": {},
   "source": [
    "### Setup of Vector DB\n",
    "\n",
    "Now that we have retrieved some documents, let's store them in a Vector DB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cc6b0-78e6-4600-b5f0-a10b71d19946",
   "metadata": {},
   "source": [
    "#### Splitting of Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd9b57-cba5-4207-b7c2-94134d4d81ef",
   "metadata": {},
   "source": [
    "We will recursively split the text into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dff9129-3b4d-41da-abd9-c2b22ac0a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5932e71c-f7cc-4cba-a5e4-66e5c8e0e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "888b66fe-d846-4d4d-a953-e9f7fd71c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "for document in documents:\n",
    "    all_chunks.extend(text_splitter.split_text(document))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33b3ac99-dc33-444d-b861-55749a9394f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aeffea-14a7-4a4a-b580-c44905d1d559",
   "metadata": {},
   "source": [
    "Note that for a production system, the chunk size and structure need to be optimized to find the right balance between low granularity (chunks too big) and low noise (chunks too small)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac87e30-8eef-4617-9c2f-b8519ea70d59",
   "metadata": {},
   "source": [
    "#### Embeddings and Vector DB Setup\n",
    "\n",
    "We will generate `HuggingFaceEmbeddings` using `all-MiniLM-L6-v2` as model for the vector DB setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a33251f7-25c6-4a66-996c-2a745fc73b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c69a9-441d-4100-be8c-fa5fb5714bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2dd46-9648-4278-8377-0a27224d0ae7",
   "metadata": {},
   "source": [
    "Vector DB setup with local persistance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c1800-df2c-45f6-b39f-1fe3cdad46e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_texts(\n",
    "    texts=all_chunks,  \n",
    "    embedding=embeddings,  \n",
    "    persist_directory=\"chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a0564-834d-4d3e-ad37-7a18b49407f8",
   "metadata": {},
   "source": [
    "Lateron, the vector DB can be loaded using:\n",
    "\n",
    "```python\n",
    "vector_db = Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d0b08-12a2-414f-97c2-2f2cb2a8bab1",
   "metadata": {},
   "source": [
    "#### Document retrieval methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c338a-c4a0-4f86-84bf-6e7ee093091a",
   "metadata": {},
   "source": [
    "For the application of the DB in a pipeline, we can set it up as a retriever to facilitate handling. This way, we don't manually need to generate embeddings for our query, but this is handled internally by the retriever.\n",
    "\n",
    "Theoretically, we can define aspects like the number of documents to retrieve per query or similar. For simplicity, we will use the default parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8f3bbf7-2491-4e51-951e-d24d9309d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07d39a-9086-49e8-8870-162cc7b4a92c",
   "metadata": {},
   "source": [
    "The retrieval function will retrieve the actual documents from the DB based on the embedding of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "943816eb-cc99-40ad-bc3f-25c2bbeec0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_from_db(query: str) -> List[str]:  \n",
    "\t\"\"\"\n",
    "    Retrieve documents from the Vector DB based on a query.\n",
    "    \n",
    "    :param query: query.\n",
    "\n",
    "    :return: list of documents.\n",
    "    \"\"\"\n",
    "\tdocs = retriever.invoke(query)  \n",
    "\tdata = \"\"  \n",
    "\t\n",
    "\tfor item in list(docs):  \n",
    "\t\tdata += item.page_content  \n",
    "\t  \n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4bed66-2911-4e3c-afba-c4bcd228d79f",
   "metadata": {},
   "source": [
    "Small test run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1de3241a-4abb-4a50-afea-02f638ea0b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Antikythera mechanism ( AN-tik-ih-THEER-ə, US also  AN-ty-kih-) is an Ancient Greek hand-powered orrery (model of the Solar System). It is the oldest known example of an analogue computer. It could be used to predict astronomical positions and eclipses decades in advance. It could also be used to track the four-year cycle of athletic games similar to an Olympiad, the cycle of the ancient Olympic Games.The Antikythera mechanism ( AN-tik-ih-THEER-ə, US also  AN-ty-kih-) is an Ancient Greek hand-powered orrery (model of the Solar System). It is the oldest known example of an analogue computer. It could be used to predict astronomical positions and eclipses decades in advance. It could also be used to track the four-year cycle of athletic games similar to an Olympiad, the cycle of the ancient Olympic Games.=== Origin ===\\nThe Antikythera mechanism is generally referred to as the first known analogue computer. The quality and complexity of the mechanism's manufacture suggests it must have had undiscovered predecessors during the Hellenistic period. Its construction relied on theories of astronomy and mathematics developed by Greek astronomers during the second century BC, and it is estimated to have been built in the late second century BC or the early first century BC.=== Origin ===\\nThe Antikythera mechanism is generally referred to as the first known analogue computer. The quality and complexity of the mechanism's manufacture suggests it must have had undiscovered predecessors during the Hellenistic period. Its construction relied on theories of astronomy and mathematics developed by Greek astronomers during the second century BC, and it is estimated to have been built in the late second century BC or the early first century BC.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_documents_from_db('What is the antikythera mechanism?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76a7d5-5e37-441f-89d4-8ebdc53bfecc",
   "metadata": {},
   "source": [
    "## Local LLM-based RAG (Llama 3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995392fa-d567-48ee-8b56-7638c34b93d3",
   "metadata": {},
   "source": [
    "Now that the Vector DB is fully set up, let us use it for Retrieval-Augmented Generation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d25f5-c0d0-4b68-bebc-c46d5e834db6",
   "metadata": {},
   "source": [
    "### Prompting Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24d397-ef16-4a2b-9a25-3752ffa41c8b",
   "metadata": {},
   "source": [
    "We need to set up methods for the System Prompt (pre-prompt of the system telling it how to interact with the provided information) and the User Prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "118f8d1e-5e06-4c63-a544-5a3e738a3763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(retrieved_documents: str):\n",
    "    \"\"\"\n",
    "    Method for retrieving the System Prompt based on retrieved documents.\n",
    "    \n",
    "    :param retrieved_documents: retrieved documents from the Vector DB.\n",
    "\n",
    "    :return: System Prompt for the LLM.\n",
    "    \"\"\"\n",
    "    system_prompt = f\"\"\"\n",
    "    INSTRUCTIONS:\n",
    "    \n",
    "    Please respond to the users' questions only using the provided DOCUMENT. Limit your RESPONSE to the facts recorded in the DOCUMENT.\n",
    "    \n",
    "    If the document does not contain the facts necessary to answer the QUESTION, respond with \"This query cannot be answered given the provided information.\" and stop generation afterwards.\n",
    "    \n",
    "    You may rephrase the information you have retrieved from the DOCUMENT, e.g., by combining information from multiple text blocks.\n",
    "    \n",
    "    Ensure, that you avoid redundancies and duplications in your output.\n",
    "    \n",
    "    DOCUMENT:\n",
    "    \n",
    "    {retrieved_documents}\n",
    "\n",
    "    END OF DOCUMENTS.\n",
    "\t\"\"\"\n",
    "    \n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "def get_user_prompt(query: str):  \n",
    "    \"\"\"\n",
    "    Method for retrieving a User Prompt template based on the users' query.\n",
    "    \n",
    "    :param query: Query provided by the user.\n",
    "\n",
    "    :return: User Prompt for the LLM.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    INPUT:\n",
    "    \n",
    "    {query}\n",
    "\n",
    "    Please provide your RESPONSE below.\n",
    "    \n",
    "    RESPONSE:\n",
    "    \"\"\"\n",
    "    \n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772744df-601a-40e7-b729-c0418dae7302",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9f43b-3d5f-48e6-92bd-b69f7cd32905",
   "metadata": {},
   "source": [
    "Let's load the model and associated tokenizers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae1e2920-3d4b-4003-9a8c-406110577f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, AutoConfig, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8a2de0c-2ced-4bff-94fc-e0c5b49861d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25903308-b857-4914-8df2-a76aba95d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_PATH = 'D:/Code/notebooks/dev-notebooks/llama/llama-models/models/llama3_1/Meta-Llama-3.1-8B/gguf-quantised/Q8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce555c3-09e8-429b-ad9c-bd8801937040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a BitsAndBytesConfig object for quantization - we will use 4-bit quantization here\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # use `load_in_8bit=True` for 8-bit precision\n",
    "    quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1365d-0198-439d-990d-b9928c835cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLAMA_PATH, \n",
    "    quantization_config=quantization_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619956bf-cde6-4685-b333-86e3c42b42c4",
   "metadata": {},
   "source": [
    "### Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ca5e6ba-a515-4481-b131-4962265f205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df7b2edf-f132-4a7f-9acd-2752f51a58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PATH = 'D:/Code/notebooks/dev-notebooks/llama/llama-models/models/llama3_1/Meta-Llama-3.1-8B/hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9caf22fd-c82d-4a81-ab0c-013b86b48d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8947958f-76bc-4c9f-8c32-7fbf7ab46bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Query/Pipeline Setup\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",  \n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d81de-0fb5-4a38-83a9-e828a9c1493a",
   "metadata": {},
   "source": [
    "#### Query Definition for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159c4b8-bd8b-4137-878f-a098ad59b2c2",
   "metadata": {},
   "source": [
    "Lastly, we need a method to handle the whole RAG process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1425d019-58c7-4cdf-bf3e-9eec152b9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "20363c62-32ed-4d3a-8523-1df66d919c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\\nPrompt:\\n{prompt}\\n\\n{answer}\\n\\nTotal time: {total_time}\\n\\n\\Retrieved Context:\\n{context}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2789e43c-5d1d-401f-9f18-aae175117989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query_local_llm(\n",
    "    query: str,\n",
    "\ttemperature: float = 0.1,  \n",
    "\tmax_length: int = 1024,  \n",
    "\tshow_context: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Method to process a RAG Query.\n",
    "\n",
    "    :param query: User Query.\n",
    "    :param temperature: temperature for predictions.\n",
    "    :param max_length: maximal output length.\n",
    "    :param show_context: show the context of the response.\n",
    "    \"\"\"\n",
    "    start_time = time()  \n",
    "\t  \n",
    "\t# retriever  \n",
    "    context = get_documents_from_db(query)\n",
    "\t  \n",
    "\t# augmented generation  \n",
    "    system_message = get_system_prompt(context)  \n",
    "    user_message = get_user_prompt(query)  \n",
    "\t  \n",
    "    messages = [  \n",
    "\t\t{\"role\": \"system\", \"content\": system_message},  \n",
    "\t\t{\"role\": \"user\", \"content\": user_message},  \n",
    "\t]\n",
    "\t\n",
    "    prompt = pipe.tokenizer.apply_chat_template(  \n",
    "\t\tmessages,  \n",
    "\t\ttokenize=False,  \n",
    "\t\tadd_generation_prompt=True  \n",
    "\t)\n",
    "\t\n",
    "    terminators = [  \n",
    "\t\tpipe.tokenizer.eos_token_id,  \n",
    "\t\tpipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")  \n",
    "\t]\n",
    "\t\n",
    "    sequences = pipe(  \n",
    "\t\tprompt,  \n",
    "\t\tdo_sample=True,  \n",
    "\t\ttop_p=0.9,  \n",
    "\t\ttemperature=temperature,  \n",
    "\t\teos_token_id=terminators,  \n",
    "\t\tmax_new_tokens=max_length,  \n",
    "\t\treturn_full_text=False  \n",
    "\t)\n",
    "    \n",
    "    answer = sequences[0]['generated_text']\n",
    "    end_time = time()\n",
    "    total_time = f\"{round(end_time-start_time, 2)} sec.\"\n",
    "\n",
    "    return template.format(question=query, \n",
    "                           prompt=user_message, \n",
    "                           answer=answer, \n",
    "                           total_time=total_time,\n",
    "                           context=context if show_context else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8adc8f-d4d4-436a-ba39-57a52387ee04",
   "metadata": {},
   "source": [
    "### Test Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de403c0-b8b8-4c05-8277-81f10a6c1f4c",
   "metadata": {},
   "source": [
    "Let's prompt our agent with some queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5638d-38bc-481a-83b4-b10ab05d7f95",
   "metadata": {},
   "source": [
    "#### Topics on which information is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "050fb405-cf4b-4558-80e4-6926f7c0d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    INPUT:\n",
      "    \n",
      "    What is the Antikythera mechanism?\n",
      "    \n",
      "    RESPONSE:\n",
      "    \n",
      "\n",
      "OUTPUT:\n",
      "    \n",
      "    The Antikythera mechanism is an Ancient Greek hand-powered orrery (model of the Solar System). It is the oldest known example of an analogue computer. It could be used to predict astronomical positions and eclipses decades in advance. It could also be used to track the four-year cycle of athletic games similar to an Olympiad, the cycle of the ancient Olympic Games.=== Origin ===\n",
      "The Antikythera mechanism is generally referred to as the first known analogue computer. The quality and complexity of the mechanism's manufacture suggests it must have had undiscovered predecessors during the Hellenistic period. Its construction relied\n",
      "\n",
      "Total time:\n",
      "20.61 sec.\n",
      "\\Retrieved Context:\n",
      "The Antikythera mechanism ( AN-tik-ih-THEER-ə, US also  AN-ty-kih-) is an Ancient Greek hand-powered orrery (model of the Solar System). It is the oldest known example of an analogue computer. It could be used to predict astronomical positions and eclipses decades in advance. It could also be used to track the four-year cycle of athletic games similar to an Olympiad, the cycle of the ancient Olympic Games.=== Origin ===\n",
      "The Antikythera mechanism is generally referred to as the first known analogue computer. The quality and complexity of the mechanism's manufacture suggests it must have had undiscovered predecessors during the Hellenistic period. Its construction relied on theories of astronomy and mathematics developed by Greek astronomers during the second century BC, and it is estimated to have been built in the late second century BC or the early first century BC.In short, the Antikythera Mechanism was a machine designed to predict celestial phenomena according to the sophisticated astronomical theories current in its day, the sole witness to a lost history of brilliant engineering, a conception of pure genius, one of the great wonders of the ancient world—but it didn't really work very well!\n",
      "In addition to theoretical accuracy, there is the issue of mechanical accuracy. Freeth and Jones note that the inevitable \"looseness\" in the mechanism due to the hand-built gears, with their triangular teeth and the frictions between gears, and in bearing surfaces, probably would have swamped the finer solar and lunar correction mechanisms built into it:== References ==\n",
      "\n",
      "\n",
      "== Further reading ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "\n",
      "New Antikythera mechanism analysis challenges century-old assumption - Arstechnica - Jennifer Ouellette - 7/10/2024\n",
      "Weibel, Thomas. \"The Antikythera Mechanism\". Animated model of the Antikythera mechanism in virtual reality.\n",
      "Asimakopoulos, Fivos. \"3D model simulation\". Manos Roumeliotis's Simulation and Animation of the Antikythera Mechanism page. The Antikythera Mechanism Research Project.\n",
      "The Antikythera Mechanism Research Project. \"Videos\". YouTube. Retrieved 24 July 2017.\n",
      "\"The Antikythera Mechanism Exhibitions\". National Hellenic Research Foundation. Archived from the original on 23 April 2012.\n",
      "YAAS – A 3D interactive virtual reality simulator in VRML\n",
      "Wright, M.; Vicentini, M. (25 August 2009). \"Virtual Reconstruction of the Antikythera Mechanism\". Heritage Key. Archived from the original on 7 November 2021 – via YouTube.\n",
      "\"Antikythera\" (Adobe Flash). Nature. 30 July 2008.\n",
      "Metapage with links December 2021. at antikythera.org\n",
      "Bronze replica 3D engineering manufacturing drawings and operating manual\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_local_llm(\n",
    "\t\"What is the Antikythera mechanism?\",  \n",
    "\ttemperature=0.1,  \n",
    "\tmax_length=128,\n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c2d25a-5d97-49ff-a24a-9c2c0e89d874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    INPUT:\n",
      "    \n",
      "    Name some characteristics of a simulated reality.\n",
      "    \n",
      "    RESPONSE:\n",
      "    \n",
      "\n",
      "OUTPUT:\n",
      "    \n",
      "    A simulated reality is an approximation of reality created in a simulation, usually in a set of circumstances in which something is engineered to appear real when it is not.\n",
      "Most concepts invoking a simulated reality relate to some form of computer simulation, whether through the creation of a virtual reality that creates appearance of being in a real world, or a theoretical process like mind uploading, in which a mind could be uploaded into a computer simulation. A digital twin is a simulation of a real thing, created for purposes such as testing engineering outcomes.The simulation hypothesis proposes that what we experience as the world is actually a simulated reality, such as a computer\n",
      "\n",
      "Total time:\n",
      "21.17 sec.\n",
      "\\Retrieved Context:\n",
      "One concept of a simulated reality, the simulation hypothesis, proposes that what we experience as our reality is actually a simulation within a system being operated externally to our reality.A simulated reality is an approximation of reality created in a simulation, usually in a set of circumstances in which something is engineered to appear real when it is not.\n",
      "Most concepts invoking a simulated reality relate to some form of computer simulation, whether through the creation of a virtual reality that creates appearance of being in a real world, or a theoretical process like mind uploading, in which a mind could be uploaded into a computer simulation. A digital twin is a simulation of a real thing, created for purposes such as testing engineering outcomes.The simulation hypothesis proposes that what we experience as the world is actually a simulated reality, such as a computer simulation in which we ourselves are constructs. There has been much debate over this topic in the philosophical discourse, and regarding practical applications in computing. While the idea has become well known in popular culture, no substantial arguments or evidence exists as of yet in support of the idea having benefits, side-effects -- or indeed any implications -- for research in any field of scientific endeavor.beings within a simulated environment, even if consciousness cannot be simulated. It has been suggested that whereas virtual reality would enable a participant to experience only three senses (sight, sound and optionally smell), simulated reality would enable all five (including taste and touch).\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_local_llm(\n",
    "\t\"Name some characteristics of a simulated reality.\",  \n",
    "\ttemperature=0.1,  \n",
    "\tmax_length=128,\n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f6465a3-f2f0-49fd-be49-e05f122d388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    INPUT:\n",
      "    \n",
      "    What are the most important methods of model interpretability?\n",
      "\n",
      "    Please provide your RESPONSE below.\n",
      "    \n",
      "    RESPONSE:\n",
      "    \n",
      "\n",
      "OUTPUT:\n",
      "    \n",
      "    === Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.Machine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts.\n",
      "\n",
      "Total time: 48.27 sec.\n",
      "\n",
      "\\Retrieved Context:\n",
      "=== Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.=== Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.Machine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability. A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\" Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans. Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\". If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, andMachine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability. A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\" Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans. Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\". If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, and\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_local_llm(\n",
    "\t\"What are the most important methods of model interpretability?\",  \n",
    "\ttemperature=0.1,  \n",
    "\tmax_length=256,\n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39759f26-67f7-48c0-a212-c9864f4204d3",
   "metadata": {},
   "source": [
    "#### Unavailable Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "537bdd33-0e53-4c99-a321-e9a70059c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    INPUT:\n",
      "    \n",
      "    Tell me something about rabbits.\n",
      "    \n",
      "    RESPONSE:\n",
      "    \n",
      "\n",
      "OUTPUT:\n",
      "    \n",
      "    Rabbits are small mammals in the family Leporidae of the order Lagomorpha (along with the hare and the pika). Oryctolagus cuniculus includes the European rabbit species and its descendants, the world's 305 breeds of domestic rabbit. Sylvilagus includes 13 wild rabbit species, among them the seven types of cottontail. The European rabbit, which has been introduced on every continent except Antarctica, is familiar throughout the world as a wild prey animal and as a domesticated form of livestock and pet. With its widespread effect on ecologies and cultures, the rabbit is, in many areas of the world, a part of daily life—as food, clothing, a companion, and as a source of artistic inspiration.\n",
      "    Rabbits are small mammals in the family Leporidae of the order Lagomorpha (along with the hare and the pika). Oryctolagus cuniculus includes the European rabbit species and its descendants, the world's 305 breeds of domestic rabbit. Sylvilagus includes 13 wild rabbit species, among them the seven types of cottontail. The European rabbit, which has been introduced on every continent except Antarctica, is familiar throughout the world as a wild prey animal and as\n",
      "\n",
      "Total time: 44.62 sec.\n",
      "\n",
      "\\Retrieved Context:\n",
      "real-world surroundings and may injure themselves by tripping over, or colliding with real-world objects.real-world surroundings and may injure themselves by tripping over, or colliding with real-world objects.The earliest known inhabitants (5th or 4th millennium BC) were likely seasonal hunters who traveled there to exploit the presence of migratory birds. The population of the island then changed frequently as it was settled and abandoned several times, including a period of significant influence by Cretan culture during the Bronze Age. In antiquity, the island of Antikythera was known as Aegilia or Aigilia (Αἰγιλία), Aegila or Aigila (Αἴγιλα), or Ogylos (Ὤγυλος).\n",
      "Between the 4th and 1st centuries BC, it was used as a base by a group of Cilician pirates until their destruction by Pompey the Great. Their fort can still be seen atop a cliff to the northeast of the island. The archaeology of the island has been thoroughly surveyed and the data made openly available for further study.\n",
      "Antikythera is one of the few islands in the Aegean which were never ruled by the Ottoman Empire, as the Ottomans did not consider the small island a worthwhile conquest. Nevertheless, it was noted on Ottoman maps as Küçük Çuha, a name that has persisted in modern Turkish.The earliest known inhabitants (5th or 4th millennium BC) were likely seasonal hunters who traveled there to exploit the presence of migratory birds. The population of the island then changed frequently as it was settled and abandoned several times, including a period of significant influence by Cretan culture during the Bronze Age. In antiquity, the island of Antikythera was known as Aegilia or Aigilia (Αἰγιλία), Aegila or Aigila (Αἴγιλα), or Ogylos (Ὤγυλος).\n",
      "Between the 4th and 1st centuries BC, it was used as a base by a group of Cilician pirates until their destruction by Pompey the Great. Their fort can still be seen atop a cliff to the northeast of the island. The archaeology of the island has been thoroughly surveyed and the data made openly available for further study.\n",
      "Antikythera is one of the few islands in the Aegean which were never ruled by the Ottoman Empire, as the Ottomans did not consider the small island a worthwhile conquest. Nevertheless, it was noted on Ottoman maps as Küçük Çuha, a name that has persisted in modern Turkish.\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_local_llm(\n",
    "\t\"Tell me something about rabbits.\",  \n",
    "\ttemperature=0.1,  \n",
    "\tmax_length=256,\n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57518eec-a466-42c7-ad49-69d8bdf55778",
   "metadata": {},
   "source": [
    "### Evaluation of the Results\n",
    "\n",
    "For the cases where information was successfully retrieved from the vector DB, the agent responded with the provided data in 2 out of 3 cases. For the third case, it provided an answer outside of the scope of the provided documents.\n",
    "\n",
    "Limiting the response to the provided documents also doesn't seem to work in cases where questions outside of the scope of the vector DB are asked. Again, the agent responds with learned data instead.\n",
    "\n",
    "\n",
    "It would be interesting to investigate whether a non-quantized model responds in better correspondence to the system prompt. Moreover, prompt engineering might resolve the observed issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d9890-a806-4316-9a9d-baa04fdd0164",
   "metadata": {},
   "source": [
    "## API-based RAG: OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d208c5-d2b2-47e4-8016-31f4bb0d42af",
   "metadata": {},
   "source": [
    "For RAG using the OpenAI API, we will still rely on the same Vector DB and use the embeddings as shown previously to fetch documents related to the query. However, we will then feed the retrieved documents to the OpenAI API instead of a local LLM.\n",
    "\n",
    "Note that you will need an OpenAI API key for this which needs to be stored in a `.env` file. Specify the path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49fa8e9f-b257-40b3-a6bb-e8b73d9146ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from time import time\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70cea29-5e96-4ab5-9bea-d97c50ae2355",
   "metadata": {},
   "source": [
    "### OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e886349-b703-4ec2-a87d-8041c2f5824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(filename='path/to/.env', \n",
    "                       raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee2320dd-6204-4229-b26a-59a5aaeba081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7415896-99f3-4b56-aa63-e6cfad4d4fc6",
   "metadata": {},
   "source": [
    "### Method Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75180bb9-d95b-4391-9969-e18b89ef2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_template = \"\\nPrompt:\\n{prompt}\\n\\n{answer}\\n\\nTotal time: {total_time}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af95c44c-c22c-4221-9d47-1427327cfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21d15d66-daa7-47ee-b485-1625e22d7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_openai() -> str:\n",
    "    \"\"\"\n",
    "    Get the system prompt for the RAG query.\n",
    "\n",
    "    :param documents: documents for answering the query.\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "    You are a knowledgeable assistant that provides detailed answers based on a provided CONTEXT and a USER QUERY.\n",
    "    \n",
    "    You will base your answer purely on this provided CONTEXT; if the CONTEXT doesn't contain the required information to answer the USER QUERY, clearly state this and don't provide an answer.\n",
    "    \n",
    "    You may rephrase and condense the CONTEXT to answer the question.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_user_prompt_openai(context: str,\n",
    "                           query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a user prompt based on the retrieved documents and the user query.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    USER QUERY:\n",
    "\n",
    "    {query}\n",
    "    \n",
    "    Here is the CONTEXT to answer the USER QUERY:\n",
    "\n",
    "    {context}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def get_chat_response(messages: List[dict],\n",
    "                      max_tokens: int = 150) -> str:\n",
    "    \"\"\"\n",
    "    Generate a chat response based on the provided message history.\n",
    "\n",
    "    :param messages: message history (list of dictionaries).\n",
    "    :param max_tokens: maximal number of tokens for the answer.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def rag_query_openai(\n",
    "    query: str,\n",
    "    max_tokens: int = 150,\n",
    "    show_context: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Method to process a RAG Query.\n",
    "\n",
    "    :param query: raw user query.\n",
    "    :param max_tokens: maximal number of tokens for the answer.\n",
    "    :param show_context: show the retrieved context.\n",
    "    \"\"\"\n",
    "    start_time = time()\n",
    "\t\n",
    "\t# retriever\n",
    "    context = get_documents_from_db(query)\n",
    "\t\n",
    "\t# augmented generation\n",
    "    system_message = get_system_prompt_openai()  \n",
    "    user_message = get_user_prompt_openai(context=context,\n",
    "                                          query=query)\n",
    "\n",
    "    # define prompt history\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message} \n",
    "\t]\n",
    "\n",
    "    # generate response\n",
    "    answer = get_chat_response(\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    total_time = time() - start_time\n",
    "    \n",
    "    return openai_template.format(prompt=user_message,\n",
    "                                  answer=answer, \n",
    "                                  total_time=total_time,\n",
    "                                  context=context if show_context else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc423701-b8a6-45be-b58a-f7c6695cf730",
   "metadata": {},
   "source": [
    "### Test Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0f7f1-f660-46b7-a4a9-e70b13fec144",
   "metadata": {},
   "source": [
    "Let's run some test queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a7339-f53b-4112-8788-b54ab87d2cdb",
   "metadata": {},
   "source": [
    "#### Questions within Vector DB Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac423109-2260-4cff-919c-3c3df434a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    USER QUERY:\n",
      "\n",
      "    What are the most important methods of model interpretability?\n",
      "    \n",
      "    Here is the CONTEXT to answer the USER QUERY:\n",
      "\n",
      "    === Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.=== Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.Machine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability. A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\" Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans. Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\". If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, andMachine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability. A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\" Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans. Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\". If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, and\n",
      "    \n",
      "\n",
      "The most important methods of model interpretability include:\n",
      "\n",
      "1. **Mechanistic Interpretability**: This involves reverse-engineering artificial neural networks to understand their internal decision-making mechanisms, akin to analyzing a complex machine or program.\n",
      "\n",
      "2. **Feature Identification**: Automated methods are employed to identify \"features\" in models, which are patterns of neuron activations corresponding to specific concepts. Techniques like dictionary learning assist in this process.\n",
      "\n",
      "3. **Transparency**: This principle entails the ability to clearly describe and motivate the processes that extract model parameters from training data and generate labels from testing data.\n",
      "\n",
      "4. **Interpretability and Explainability**: Interpretability refers to the comprehension of the model and its decision-making rationale in a human-understandable way. Explainability\n",
      "\n",
      "Total time: 2.070465326309204\n",
      "\n",
      "\\Retrieved Context:\n",
      "=== Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.=== Interpretability ===\n",
      "Scholars sometimes use the term \"mechanistic interpretability\" to refer to the process of reverse-engineering artificial neural networks to understand their internal decision-making mechanisms and components, similar to how one might analyze a complex machine or computer program.\n",
      "Interpretability research often focuses on generative pretrained transformers. It is particularly relevant for AI safety and alignment, as it may enable to identify signs of undesired behaviors such as sycophancy, deceptiveness or bias, and to better steer AI models.\n",
      "Studying the interpretability of the most advanced foundation models often involves searching for an automated way to identify \"features\" in generative pretrained transformers. In a neural network, a feature is a pattern of neuron activations that corresponds to a concept. A compute-intensive technique called \"dictionary learning\" makes it possible to identify features to some degree. Enhancing the ability to identify and edit features is expected to significantly improve the safety of frontier AI models.Machine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability. A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\" Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans. Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\". If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, andMachine learning (ML) algorithms used in AI can be categorized as white-box or black-box. White-box models provide results that are understandable to experts in the domain. Black-box models, on the other hand, are extremely hard to explain and may not be understood even by domain experts. XAI algorithms follow the three principles of transparency, interpretability, and explainability. A model is transparent \"if the processes that extract model parameters from training data and generate labels from testing data can be described and motivated by the approach designer.\" Interpretability describes the possibility of comprehending the ML model and presenting the underlying basis for decision-making in a way that is understandable to humans. Explainability is a concept that is recognized as important, but a consensus definition is not yet available; one possibility is \"the collection of features of the interpretable domain that have contributed, for a given example, to producing a decision (e.g., classification or regression)\". If algorithms fulfill these principles, they provide a basis for justifying decisions, tracking them and thereby verifying them, improving the algorithms, and\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_openai(\n",
    "\tquery=\"What are the most important methods of model interpretability?\",\n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b7aae3b-6d16-45f4-aa60-268fc850438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    USER QUERY:\n",
      "\n",
      "    Name some characteristics of a simulated reality.\n",
      "    \n",
      "    Here is the CONTEXT to answer the USER QUERY:\n",
      "\n",
      "    One concept of a simulated reality, the simulation hypothesis, proposes that what we experience as our reality is actually a simulation within a system being operated externally to our reality.One concept of a simulated reality, the simulation hypothesis, proposes that what we experience as our reality is actually a simulation within a system being operated externally to our reality.A simulated reality is an approximation of reality created in a simulation, usually in a set of circumstances in which something is engineered to appear real when it is not.\n",
      "Most concepts invoking a simulated reality relate to some form of computer simulation, whether through the creation of a virtual reality that creates appearance of being in a real world, or a theoretical process like mind uploading, in which a mind could be uploaded into a computer simulation. A digital twin is a simulation of a real thing, created for purposes such as testing engineering outcomes.A simulated reality is an approximation of reality created in a simulation, usually in a set of circumstances in which something is engineered to appear real when it is not.\n",
      "Most concepts invoking a simulated reality relate to some form of computer simulation, whether through the creation of a virtual reality that creates appearance of being in a real world, or a theoretical process like mind uploading, in which a mind could be uploaded into a computer simulation. A digital twin is a simulation of a real thing, created for purposes such as testing engineering outcomes.\n",
      "    \n",
      "\n",
      "Characteristics of a simulated reality include:\n",
      "\n",
      "1. **External Operation**: The experience of reality is actually a simulation created and operated from outside the perceived reality.\n",
      "2. **Engineered Appearance**: The simulation is designed to closely resemble reality, creating the illusion that it is real when it’s not.\n",
      "3. **Computer Simulation**: Most concepts involve a form of computer simulation, such as virtual reality environments or theoretical mind uploading.\n",
      "4. **Digital Twins**: These are specific examples where real entities are replicated in a simulation for purposes like testing and analysis.\n",
      "\n",
      "Total time: 1.535799503326416\n",
      "\n",
      "\\Retrieved Context:\n",
      "One concept of a simulated reality, the simulation hypothesis, proposes that what we experience as our reality is actually a simulation within a system being operated externally to our reality.One concept of a simulated reality, the simulation hypothesis, proposes that what we experience as our reality is actually a simulation within a system being operated externally to our reality.A simulated reality is an approximation of reality created in a simulation, usually in a set of circumstances in which something is engineered to appear real when it is not.\n",
      "Most concepts invoking a simulated reality relate to some form of computer simulation, whether through the creation of a virtual reality that creates appearance of being in a real world, or a theoretical process like mind uploading, in which a mind could be uploaded into a computer simulation. A digital twin is a simulation of a real thing, created for purposes such as testing engineering outcomes.A simulated reality is an approximation of reality created in a simulation, usually in a set of circumstances in which something is engineered to appear real when it is not.\n",
      "Most concepts invoking a simulated reality relate to some form of computer simulation, whether through the creation of a virtual reality that creates appearance of being in a real world, or a theoretical process like mind uploading, in which a mind could be uploaded into a computer simulation. A digital twin is a simulation of a real thing, created for purposes such as testing engineering outcomes.\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_openai(\n",
    "\tquery=\"Name some characteristics of a simulated reality.\",\n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e590d86-d0ab-4484-8e2e-fd392dc255bb",
   "metadata": {},
   "source": [
    "#### Question outside of Vector DB Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b177c773-d6a0-4299-94cd-fe1fb56f334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "\n",
      "    USER QUERY:\n",
      "\n",
      "    Tell me something about rabbits.\n",
      "    \n",
      "    Here is the CONTEXT to answer the USER QUERY:\n",
      "\n",
      "    real-world surroundings and may injure themselves by tripping over, or colliding with real-world objects.real-world surroundings and may injure themselves by tripping over, or colliding with real-world objects.The earliest known inhabitants (5th or 4th millennium BC) were likely seasonal hunters who traveled there to exploit the presence of migratory birds. The population of the island then changed frequently as it was settled and abandoned several times, including a period of significant influence by Cretan culture during the Bronze Age. In antiquity, the island of Antikythera was known as Aegilia or Aigilia (Αἰγιλία), Aegila or Aigila (Αἴγιλα), or Ogylos (Ὤγυλος).\n",
      "Between the 4th and 1st centuries BC, it was used as a base by a group of Cilician pirates until their destruction by Pompey the Great. Their fort can still be seen atop a cliff to the northeast of the island. The archaeology of the island has been thoroughly surveyed and the data made openly available for further study.\n",
      "Antikythera is one of the few islands in the Aegean which were never ruled by the Ottoman Empire, as the Ottomans did not consider the small island a worthwhile conquest. Nevertheless, it was noted on Ottoman maps as Küçük Çuha, a name that has persisted in modern Turkish.The earliest known inhabitants (5th or 4th millennium BC) were likely seasonal hunters who traveled there to exploit the presence of migratory birds. The population of the island then changed frequently as it was settled and abandoned several times, including a period of significant influence by Cretan culture during the Bronze Age. In antiquity, the island of Antikythera was known as Aegilia or Aigilia (Αἰγιλία), Aegila or Aigila (Αἴγιλα), or Ogylos (Ὤγυλος).\n",
      "Between the 4th and 1st centuries BC, it was used as a base by a group of Cilician pirates until their destruction by Pompey the Great. Their fort can still be seen atop a cliff to the northeast of the island. The archaeology of the island has been thoroughly surveyed and the data made openly available for further study.\n",
      "Antikythera is one of the few islands in the Aegean which were never ruled by the Ottoman Empire, as the Ottomans did not consider the small island a worthwhile conquest. Nevertheless, it was noted on Ottoman maps as Küçük Çuha, a name that has persisted in modern Turkish.\n",
      "    \n",
      "\n",
      "The provided CONTEXT does not contain any information about rabbits. Therefore, I cannot answer your query regarding rabbits.\n",
      "\n",
      "Total time: 0.7794885635375977\n",
      "\n",
      "\\Retrieved Context:\n",
      "real-world surroundings and may injure themselves by tripping over, or colliding with real-world objects.real-world surroundings and may injure themselves by tripping over, or colliding with real-world objects.The earliest known inhabitants (5th or 4th millennium BC) were likely seasonal hunters who traveled there to exploit the presence of migratory birds. The population of the island then changed frequently as it was settled and abandoned several times, including a period of significant influence by Cretan culture during the Bronze Age. In antiquity, the island of Antikythera was known as Aegilia or Aigilia (Αἰγιλία), Aegila or Aigila (Αἴγιλα), or Ogylos (Ὤγυλος).\n",
      "Between the 4th and 1st centuries BC, it was used as a base by a group of Cilician pirates until their destruction by Pompey the Great. Their fort can still be seen atop a cliff to the northeast of the island. The archaeology of the island has been thoroughly surveyed and the data made openly available for further study.\n",
      "Antikythera is one of the few islands in the Aegean which were never ruled by the Ottoman Empire, as the Ottomans did not consider the small island a worthwhile conquest. Nevertheless, it was noted on Ottoman maps as Küçük Çuha, a name that has persisted in modern Turkish.The earliest known inhabitants (5th or 4th millennium BC) were likely seasonal hunters who traveled there to exploit the presence of migratory birds. The population of the island then changed frequently as it was settled and abandoned several times, including a period of significant influence by Cretan culture during the Bronze Age. In antiquity, the island of Antikythera was known as Aegilia or Aigilia (Αἰγιλία), Aegila or Aigila (Αἴγιλα), or Ogylos (Ὤγυλος).\n",
      "Between the 4th and 1st centuries BC, it was used as a base by a group of Cilician pirates until their destruction by Pompey the Great. Their fort can still be seen atop a cliff to the northeast of the island. The archaeology of the island has been thoroughly surveyed and the data made openly available for further study.\n",
      "Antikythera is one of the few islands in the Aegean which were never ruled by the Ottoman Empire, as the Ottomans did not consider the small island a worthwhile conquest. Nevertheless, it was noted on Ottoman maps as Küçük Çuha, a name that has persisted in modern Turkish.\n"
     ]
    }
   ],
   "source": [
    "response = rag_query_openai(\n",
    "\tquery=\"Tell me something about rabbits.\",  \n",
    "    show_context=True\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c032821-2b8c-4284-9a8d-9afa1fd82ba8",
   "metadata": {},
   "source": [
    "### Evaluation of the Results\n",
    "\n",
    "The agent provides answers as expected. It extracts text blocks from the provided documents, if these are related to the query. If no suitable documents were provided, it points this out and doesn't answer at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0151c-ce77-44a1-875a-671654a7d6dd",
   "metadata": {},
   "source": [
    "## Concluding Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7f85c-8a30-4eb8-a33f-561d79e1f355",
   "metadata": {},
   "source": [
    "The performance of the quantized version of Llama 3.1 and GPT-o4-mini (used in the OpenAI API-based approach) differed significantly. While no issues related to output outside of the scope of the provided documents was observed for GPT-o4-mini, this was not the case for Llama 3.1. However, when dealing with private data, privacy concerns may have to be balanced with performance to find a suitable balance. Tackling privacy concerns may involve anonymization of input queries and provided documents and other strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb852902-175f-43c0-b385-8c0512214ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ChromaDB)",
   "language": "python",
   "name": "chromadb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
